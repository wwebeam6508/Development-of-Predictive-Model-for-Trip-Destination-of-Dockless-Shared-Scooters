{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "census_by_community = gpd.read_file('Data/census_by_community1.shp')\n",
    "grid_data = gpd.read_file('Data/ScooterGridId.shp')\n",
    "data = pd.read_csv('Data/ScooterData_July15_Sept27_2019.csv')\n",
    "\n",
    "data_point = data[['startx','starty']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_point' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4b1b2539ca6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdata_from_census\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprogressbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogressbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_point\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcensus_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcensus_by_community\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mPoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_point\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwithin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcensus_by_community\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcensus_i\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_point' is not defined"
     ]
    }
   ],
   "source": [
    "import progressbar\n",
    "from shapely.geometry import Polygon, Point\n",
    "\n",
    "data_from_census = []\n",
    "\n",
    "for i in progressbar.progressbar(range(len(data_point))):\n",
    "    for census_i in range(len(census_by_community)):\n",
    "        if Point(data_point[i]).within(census_by_community.geometry[census_i]) == True :\n",
    "            cd = census_by_community\n",
    "            data_from_census.append([cd.apartment[census_i], cd.apt_na[census_i], cd.apt_no_res[census_i], cd.apt_occpd[census_i], cd.apt_owned[census_i], cd.apt_person[census_i]\n",
    "                                    , cd.apt_uc[census_i], cd.apt_vacant[census_i]\n",
    "                                    , cd['class'][census_i]\n",
    "                                    , cd.cnv_na[census_i], cd.cnv_no_res[census_i], cd.cnv_occpd[census_i], cd.cnv_owned[census_i], cd.cnv_person[census_i]\n",
    "                                    , cd.cnv_uc[census_i], cd.cnv_vacant[census_i]\n",
    "                                    , cd.comunl_hse[census_i]\n",
    "                                    , cd.conv_struc[census_i]\n",
    "                                    , cd.dog_cnt[census_i]\n",
    "                                    , cd.dup_na[census_i], cd.dup_no_res[census_i], cd.dup_occpd[census_i], cd.dup_owned[census_i], cd.dup_person[census_i]\n",
    "                                    , cd.dup_uc[census_i], cd.dup_vacant[census_i]\n",
    "                                    , cd.dwell_cnt[census_i]\n",
    "                                    , cd.fem_0_4[census_i], cd.fem_5_14[census_i], cd.fem_15_19[census_i], cd.fem_20_24[census_i], cd.fem_25_34[census_i], cd.fem_35_44[census_i]\n",
    "                                    , cd.fem_45_54[census_i], cd.fem_55_64[census_i], cd.fem_65_74[census_i], cd.fem_75[census_i], cd.female_cnt[census_i]\n",
    "                                    , cd.male_0_4[census_i], cd.male_5_14[census_i], cd.male_15_19[census_i], cd.male_20_24[census_i], cd.male_25_34[census_i], cd.male_35_44[census_i]\n",
    "                                    , cd.male_45_54[census_i], cd.male_55_64[census_i], cd.male_65_74[census_i], cd.male_75[census_i], cd.male_cnt[census_i]\n",
    "                                    , cd.nursing_hm[census_i]\n",
    "                                    , cd.sing_famly[census_i]\n",
    "                                    , cd.town_house[census_i], cd.twn_na[census_i], cd.twn_no_res[census_i], cd.twn_occpd[census_i], cd.twn_owned[census_i], cd.twn_person[census_i]\n",
    "                                    , cd.twn_uc[census_i], cd.twn_vacant[census_i]])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_from_census_numpy = np.array(data_from_census)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"metadata.csv\", data_from_census_numpy , delimiter='  ', comments='', fmt='%s') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_data = data[['start_date', 'start_hour', 'start_day_of_week']].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"datedata.csv\", date_data , delimiter='  ', comments='', fmt='%s') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (459478 of 459478) |################| Elapsed Time: 0:05:50 Time:  0:05:50\n",
      "100% (459478 of 459478) |################| Elapsed Time: 0:05:47 Time:  0:05:47\n"
     ]
    }
   ],
   "source": [
    "import progressbar\n",
    "from shapely.geometry import shape, Polygon, Point\n",
    "grid_start_coor = []\n",
    "centeroid_grid = [[round(x.centroid.x,2), round(x.centroid.y,2)] for x in grid_data.geometry]\n",
    "centeroid_scale_grid = [[x.centroid.x, x.centroid.y] for x in grid_data.geometry]\n",
    "start_coor = [[round(x.startx,2), round(x.starty,2)] for x in data.itertuples()]\n",
    "end_coor = [[round(x.endx,2), round(x.endy,2)] for x in data.itertuples()]\n",
    "# for data_i in progressbar.progressbar(range(len(data))):\n",
    "start_re_coor = []\n",
    "end_re_coor = []\n",
    "for i in progressbar.progressbar(range(len(start_coor))):\n",
    "    for j in range(len(centeroid_grid)):\n",
    "        if start_coor[i][0] == centeroid_grid[j][0] and start_coor[i][1] == centeroid_grid[j][1]:\n",
    "            start_re_coor.append(centeroid_scale_grid[j])\n",
    "            break;\n",
    "for i in progressbar.progressbar(range(len(end_coor))):\n",
    "    for j in range(len(centeroid_grid)):\n",
    "        if end_coor[i][0] == centeroid_grid[j][0] and end_coor[i][1] == centeroid_grid[j][1]:\n",
    "            end_re_coor.append(centeroid_scale_grid[j])\n",
    "            break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar\n",
    "from shapely.geometry import shape, Polygon, Point\n",
    "import pandas as pd\n",
    "grid_start_coor = []\n",
    "centeroid_grid = [[round(x.centroid.x,2), round(x.centroid.y,2)] for x in grid_data.geometry]\n",
    "centeroid_scale_grid = [[x.centroid.x, x.centroid.y] for x in grid_data.geometry]\n",
    "start_coor = [[round(x.startx,2), round(x.starty,2)] for x in data.itertuples()]\n",
    "end_coor = [[round(x.endx,2), round(x.endy,2)] for x in data.itertuples()]\n",
    "\n",
    "dataplot = pd.DataFrame(np.array(centeroid_scale_grid),columns=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "census_by_community = gpd.read_file('Data/census_by_community1.shp')\n",
    "grid_data = gpd.read_file('Data/ScooterGridId.shp')\n",
    "data = pd.read_csv('Data/ScooterData_July15_Sept27_2019.csv')\n",
    "\n",
    "data_point = data[['startx','starty']].to_numpy()\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters = 100, max_iter=1000, init ='k-means++')\n",
    "\n",
    "lat_long = np.array(centeroid_scale_grid)\n",
    "lot_size = len(centeroid_scale_grid)\n",
    "weighted_kmeans_clusters = kmeans.fit(lat_long, sample_weight = lot_size) # Compute k-means clustering.\n",
    "c_group = kmeans.predict(lat_long, sample_weight = lot_size)\n",
    "\n",
    "start_c_group = []\n",
    "end_c_group = []\n",
    "for i in progressbar.progressbar(range(len(start_coor))):\n",
    "    for j in range(len(centeroid_grid)):\n",
    "        if start_coor[i][0] == centeroid_grid[j][0] and start_coor[i][1] == centeroid_grid[j][1]:\n",
    "            start_c_group.append(c_group[j])\n",
    "            break;\n",
    "for i in progressbar.progressbar(range(len(end_coor))):\n",
    "    for j in range(len(centeroid_grid)):\n",
    "        if end_coor[i][0] == centeroid_grid[j][0] and end_coor[i][1] == centeroid_grid[j][1]:\n",
    "            end_c_group.append(c_group[j])\n",
    "            break;\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "centers = kmeans.cluster_centers_ # Coordinates of cluster centers.\n",
    "labels = c_group # Labels of each point\n",
    "\n",
    "dataplot.plot.scatter(x = 'x', y = 'y', c=labels, s=50, cmap='viridis')\n",
    "# plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)\n",
    "plt.title('Clustering GPS Co-ordinates to Form Regions - Weighted',fontsize=10, fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_c_group = []\n",
    "end_c_group = []\n",
    "for i in progressbar.progressbar(range(len(start_coor))):\n",
    "    for j in range(len(centeroid_grid)):\n",
    "        if start_coor[i][0] == centeroid_grid[j][0] and start_coor[i][1] == centeroid_grid[j][1]:\n",
    "            start_c_group.append(c_group[j])\n",
    "            break;\n",
    "for i in progressbar.progressbar(range(len(end_coor))):\n",
    "    for j in range(len(centeroid_grid)):\n",
    "        if end_coor[i][0] == centeroid_grid[j][0] and end_coor[i][1] == centeroid_grid[j][1]:\n",
    "            end_c_group.append(c_group[j])\n",
    "            break;\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "centers = kmeans.cluster_centers_ # Coordinates of cluster centers.\n",
    "labels = c_group # Labels of each point\n",
    "\n",
    "dataplot.plot.scatter(x = 'x', y = 'y', c=labels, s=50, cmap='viridis')\n",
    "# plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)\n",
    "plt.title('Clustering GPS Co-ordinates to Form Regions - Weighted',fontsize=10, fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "coor_data = np.concatenate((data[['startx', 'starty', 'endx', 'endy']], start_re_coor), axis=1)\n",
    "coor_data = np.concatenate((coor_data, end_re_coor), axis=1)\n",
    "\n",
    "start_c_group = np.reshape(start_c_group, (len(start_c_group), 1))\n",
    "end_c_group = np.reshape(end_c_group, (len(end_c_group), 1))\n",
    "cluster_data = np.concatenate((end_c_group, start_c_group), axis=1)\n",
    "coor_data = np.concatenate((coor_data, cluster_data), axis=1)\n",
    "np.savetxt(\"Data/coordata.csv\", coor_data , delimiter='  ', comments='', fmt='%s') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
